import argparse
import os
from tqdm import tqdm
import logging
from simalign import SentenceAligner

def get_word_alignments(source_sent, target_sent, aligner, matching_methods='mai'):
    """
    Extrahiert Wort-Alignments mit SimAlign.

    Args:
        source_sent (str): Der Quellsatz (Deutsch).
        target_sent (str): Der Zielsatz (Englisch).
        aligner (SentenceAligner): Der konfigurierte SimAlign SentenceAligner.
        matching_methods (str): Die zu verwendenden Matching-Methoden.
                               'm' = max, 'a' = argmax, 'i' = inter

    Returns:
        list: Eine Liste von Tupeln, die die alignierten Wort-Indizes repräsentieren,
              z.B. [(0, 0), (1, 2)] im Format (source_idx, target_idx)
    """
    try:
        # SimAlign erwartet Listen von Wörtern
        source_words = source_sent.split()
        target_words = target_sent.split()
        
        # Leere Sätze abfangen
        if not source_words or not target_words:
            return []
        
        # Alignments mit SimAlign generieren
        alignments = aligner.get_word_aligns(source_words, target_words)
        
        # Das Ergebnis ist ein Dictionary mit den verschiedenen Methoden
        # Wir verwenden standardmäßig 'inter' (intersection), falls verfügbar
        if 'inter' in alignments and matching_methods.find('i') != -1:
            alignment_pairs = alignments['inter']
        elif 'mwmf' in alignments and matching_methods.find('a') != -1:
            alignment_pairs = alignments['mwmf']  # Argmax (mwmf = max weight matching forward)
        elif 'forward' in alignments and matching_methods.find('m') != -1:
            alignment_pairs = alignments['forward']  # Max
        else:
            # Fallback auf das erste verfügbare Alignment
            alignment_pairs = list(alignments.values())[0] if alignments else []
        
        return alignment_pairs
        
    except Exception as e:
        logging.warning(f"Fehler beim Alignment-Prozess: {e}")
        return []


def process_files(source_file, target_file, output_file, model_name='bert-base-multilingual-cased', 
                 matching_methods='mai', token_type='word', distortion=0.0, max_lines=None):
    """
    Verarbeitet parallele Textdateien und erstellt Wort-Alignments mit SimAlign.
    
    Args:
        source_file (str): Pfad zur Quelldatei (Deutsch)
        target_file (str): Pfad zur Zieldatei (Englisch)
        output_file (str): Pfad für die Ausgabedatei mit Alignments
        model_name (str): Name des zu verwendenden Embedding-Modells
        matching_methods (str): Matching-Methoden ('m'=max, 'a'=argmax, 'i'=inter)
        token_type (str): Token-Typ ('word' oder 'bpe')
        distortion (float): Distortion-Parameter für strukturelle Ähnlichkeit
        max_lines (int): Maximale Anzahl zu verarbeitender Zeilen (None für alle)
    """
    print("=== SimAlign Word Alignment Generator ===")
    print("Initialisiere SimAlign...")
    print(f"Modell: {model_name}")
    print(f"Matching-Methoden: {matching_methods}")
    print(f"Token-Typ: {token_type}")
    print(f"Distortion-Parameter: {distortion}")
    print()

    # SimAlign SentenceAligner initialisieren
    try:
        aligner = SentenceAligner(
            model=model_name,
            token_type=token_type,
            matching_methods=matching_methods,
            device='cuda' if os.environ.get('CUDA_VISIBLE_DEVICES') else 'cpu'
        )
        print("SimAlign erfolgreich initialisiert.")
        print(f"Verwendetes Gerät: {aligner.device}")
        print()
    except Exception as e:
        print(f"Fehler beim Initialisieren von SimAlign: {e}")
        print("Stelle sicher, dass SimAlign installiert ist: pip install simalign")
        exit(1)

    # Dateien öffnen und verarbeiten
    with open(source_file, 'r', encoding='utf-8') as src_f, \
         open(target_file, 'r', encoding='utf-8') as tgt_f, \
         open(output_file, 'w', encoding='utf-8') as out_f:
        
        # Header für die Ausgabedatei schreiben
        out_f.write("# Word alignments generated by SimAlign\n")
        out_f.write(f"# Model: {model_name}\n")
        out_f.write(f"# Matching methods: {matching_methods}\n")
        out_f.write(f"# Token type: {token_type}\n")
        out_f.write(f"# Distortion: {distortion}\n")
        out_f.write("# Format: source_word_index-target_word_index (0-indexed)\n")
        out_f.write("# Each line corresponds to one sentence pair\n\n")
        
        # Zeilen zählen für Fortschrittsanzeige
        if max_lines is None:
            print("Zähle Zeilen...")
            with open(source_file, 'r', encoding='utf-8') as temp_f:
                total_lines = sum(1 for _ in temp_f)
        else:
            total_lines = max_lines
            
        print(f"Verarbeite {total_lines} Satzpaare...")
        
        # Verarbeitung mit Fortschrittsanzeige
        processed_lines = 0
        error_lines = 0
        
        with tqdm(total=total_lines, desc="Processing") as pbar:
            for line_num, (src_line, tgt_line) in enumerate(zip(src_f, tgt_f)):
                if max_lines and line_num >= max_lines:
                    break
                
                # Zeilen säubern
                src_sent = src_line.strip()
                tgt_sent = tgt_line.strip()
                
                # Leere Zeilen überspringen
                if not src_sent or not tgt_sent:
                    out_f.write("\n")
                    pbar.update(1)
                    continue
                
                try:
                    # Alignments generieren
                    alignments = get_word_alignments(src_sent, tgt_sent, aligner, matching_methods)
                    
                    # Alignments im Pharaoh-Format ausgeben (source-target)
                    if alignments:
                        alignment_str = " ".join([f"{src_idx}-{tgt_idx}" for src_idx, tgt_idx in alignments])
                        out_f.write(f"{alignment_str}\n")
                    else:
                        out_f.write("\n")  # Keine Alignments gefunden
                    
                    processed_lines += 1
                    
                except Exception as e:
                    print(f"\nFehler bei Zeile {line_num + 1}: {e}")
                    out_f.write("# ERROR IN THIS LINE\n")
                    error_lines += 1
                
                pbar.update(1)
                
                # Zwischenspeichern alle 1000 Zeilen
                if (line_num + 1) % 1000 == 0:
                    out_f.flush()
    
    print(f"\nVerarbeitung abgeschlossen!")
    print(f"Erfolgreich verarbeitete Zeilen: {processed_lines}")
    print(f"Fehlerhafte Zeilen: {error_lines}")
    print(f"Alignments gespeichert in: {output_file}")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='SimAlign-basierte Wort-Alignment-Generierung')
    
    # Eingabe-/Ausgabedateien
    parser.add_argument('--source_file', '-s', default='../../Corpus/TEST_DATA/TEST_DATA.de', 
                        help='Pfad zur Quelldatei (Deutsch)')
    parser.add_argument('--target_file', '-t', default='../../Corpus/TEST_DATA/TEST_DATA.en', 
                        help='Pfad zur Zieldatei (Englisch)')
    parser.add_argument('--output_file', '-o', default='simalign_alignments.txt', 
                        help='Pfad für die Ausgabedatei')
    
    # SimAlign-spezifische Parameter
    parser.add_argument('--model_name', '-m', default='bert-base-multilingual-cased', 
                        help='Name des Embedding-Modells (z.B. bert-base-multilingual-cased, xlm-roberta-base)')
    parser.add_argument('--matching_methods', default='mai', 
                        help='Matching-Methoden: m=max, a=argmax, i=inter (default: mai für alle)')
    parser.add_argument('--token_type', default='word', choices=['word', 'bpe'],
                        help='Token-Typ: word für Wort-Level, bpe für Subword-Level (default: word)')
    parser.add_argument('--distortion', type=float, default=0.0, 
                        help='Distortion-Parameter für strukturelle Ähnlichkeit (default: 0.0)')
    
    # Weitere Parameter
    parser.add_argument('--max_lines', type=int, default=None, 
                        help='Maximale Anzahl zu verarbeitender Zeilen (für Tests)')
    parser.add_argument('--verbose', '-v', action='store_true',
                        help='Verbose-Ausgabe aktivieren')
    
    args = parser.parse_args()
    
    # Logging konfigurieren
    if args.verbose:
        logging.basicConfig(level=logging.INFO)
    else:
        logging.basicConfig(level=logging.WARNING)
    
    # Überprüfung der Eingabedateien
    if not os.path.exists(args.source_file):
        print(f"Fehler: Quelldatei '{args.source_file}' nicht gefunden!")
        exit(1)
    if not os.path.exists(args.target_file):
        print(f"Fehler: Zieldatei '{args.target_file}' nicht gefunden!")
        exit(1)
    
    print("=== SimAlign Parameter Summary ===")
    print(f"Quelldatei (DE): {args.source_file}")
    print(f"Zieldatei (EN): {args.target_file}")
    print(f"Ausgabedatei: {args.output_file}")
    print(f"Modell: {args.model_name}")
    print(f"Matching-Methoden: {args.matching_methods}")
    print(f"Token-Typ: {args.token_type}")
    print(f"Distortion: {args.distortion}")
    if args.max_lines:
        print(f"Maximale Zeilen: {args.max_lines}")
    print()
    
    # Verarbeitung starten
    process_files(args.source_file, args.target_file, args.output_file, 
                  args.model_name, args.matching_methods, args.token_type, 
                  args.distortion, args.max_lines) 